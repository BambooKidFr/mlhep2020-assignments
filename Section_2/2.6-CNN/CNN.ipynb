{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBE9GIubrYDC"
   },
   "source": [
    "# Deep learning for computer vision\n",
    "\n",
    "\n",
    "This notebook will teach you to build and train convolutional networks for image recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "umUCOiHFrYDk",
    "outputId": "4703515a-c483-4375-a7ea-1c2bf9260426"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import functools\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "ds1 = datasets.FashionMNIST(\"../../data\", train=True, download=True, transform=transform)\n",
    "ds_test = datasets.FashionMNIST(\"../../data\", train=False, download=True, transform=transform)\n",
    "\n",
    "ds_train, ds_val = torch.utils.data.random_split(ds1, [50000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(ds_train, batch_size=32,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(ds_val, batch_size=10000,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(ds_test, batch_size=10000,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print(\"Training+Val:\", ds1,\n",
    "     \"\\nTest:\", ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_free_gpu():\n",
    "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount\n",
    "    nvmlInit()\n",
    "\n",
    "    return np.argmax([\n",
    "        nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(i)).free\n",
    "        for i in range(nvmlDeviceGetCount())\n",
    "    ])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_id = get_free_gpu()\n",
    "    device = 'cuda:%d' % (get_free_gpu(), )\n",
    "    print('Selected %s' % (device, ))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('WARNING: using cpu!')\n",
    "\n",
    "### please, don't remove the following line\n",
    "x = torch.tensor([1], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MM8T9MISrYEM"
   },
   "source": [
    "# Building a baseline network\n",
    "\n",
    "Simple neural networks with layers applied on top of one another can be implemented either as `torch.nn.Sequential` or as a subclass of `torch.nn.Module`. \n",
    "\n",
    "__Convolutional layers__ in torch are just like all other layers, but with a specific set of parameters:\n",
    "\n",
    "__`nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)`__\n",
    "\n",
    "__`nn.MaxPool2d(kernel_size)`__\n",
    "\n",
    "Let's start with a simple baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f43dEPxzrYEb"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(676, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xk4XvZcBrYEk"
   },
   "source": [
    "As in our basic tutorial, we train our model with negative log-likelihood aka crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_count_params(model):\n",
    "    return np.sum([s.numel() for s in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0RGtIAirYE0"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/F-MNIST_CNN-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "writer.add_scalar(\"model/size\", model_count_params(model))\n",
    "print(\"Model size:\", model_count_params(model))\n",
    "writer.add_graph(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bae8d3947a53b72be94cf1e9be3700c",
     "grade": false,
     "grade_id": "cell-4dc4a1834191d4dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculates the accuracy of the prediction\n",
    "    y_true is N-vector of integers for N-item batch\n",
    "    y_pred is a tensor N x 10 of 10-dimensional network component output\n",
    "    \n",
    "    You have to find the number of the highest component output\n",
    "    and compare it with y_true and compute average number of exact matches.\n",
    "    \n",
    "    Returs: average number of exact matches \n",
    "    \"\"\"\n",
    "    # to find maximum item in the tensor along i dimension use .max(dim=i)\n",
    "    # to count number of matching items use '==' operator\n",
    "    # \n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ddccf6f40cbb945c3c2184101fcaaa7",
     "grade": true,
     "grade_id": "accuracy_proc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert accuracy(torch.ones(1000), torch.rand(1000,2)) > 0.4 \n",
    "assert accuracy(torch.ones(1000), torch.rand(1000,2)) < 0.6\n",
    "assert accuracy(torch.ones(10), torch.cat([torch.ones(10,1), torch.zeros(10,1)], dim=1)) == 0\n",
    "assert accuracy(torch.ones(10), torch.cat([torch.zeros(10,1), torch.ones(10,1)], dim=1)) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, writer, num_epochs=1):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss = []\n",
    "    test_accuracy = []\n",
    "    running_loss = 0\n",
    "    epoch_iter = tqdm.trange(num_epochs)\n",
    "    for epoch in epoch_iter:\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                writer.add_scalar('Loss/training',\n",
    "                                running_loss / 1000,\n",
    "                                epoch * len(trainloader) + i)\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in DataLoader(ds_val, batch_size=len(ds_val)):\n",
    "            test_accuracy.append(\n",
    "                accuracy(\n",
    "                    y_batch,\n",
    "                    model(X_batch)))\n",
    "\n",
    "        writer.add_scalar('Loss/val',\n",
    "                            test_accuracy[-1],\n",
    "                            epoch)\n",
    "        epoch_iter.set_description(f\"Accuracy: {test_accuracy[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, writer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJy3BBGKrYFE"
   },
   "source": [
    "### Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iKXTHsCrYFG",
    "outputId": "2521b0c1-877e-4350-e207-075537737ea3"
   },
   "outputs": [],
   "source": [
    "def test_model(model, writer):\n",
    "    test_accuracy = 0\n",
    "    model.train(False) \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in DataLoader(ds_test, batch_size=len(ds_test)):\n",
    "            test_accuracy = 100 * accuracy(y_batch, model(X_batch))\n",
    "\n",
    "\n",
    "    print(\"Final results:\")\n",
    "    print(f\"  test accuracy:\\t\\t{test_accuracy:.2f}\")\n",
    "\n",
    "    if test_accuracy > 98:\n",
    "        print(\"U'r freakin' amazin'!\")\n",
    "    elif test_accuracy > 95:\n",
    "        print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "    elif test_accuracy > 90:\n",
    "        print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "    elif test_accuracy > 85:\n",
    "        print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "    else:\n",
    "        print(\"We need more magic! Follow instructons below\")\n",
    "    writer.add_scalar(\"Loss/test\", test_accuracy)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b26b1668691e9e87fa54a30365eadd2",
     "grade": true,
     "grade_id": "model_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%time acc = test_model(model, writer)\n",
    "assert acc > 80\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmFLssyIrYFS"
   },
   "source": [
    "## Task: improve convolution net\n",
    "\n",
    "Let's create a mini-convolutional network with an architecture like this:\n",
    "\n",
    "* 3x3 convolution with 8 filters, padding=1 and _ReLU_ activation\n",
    "* 2x2 pooling\n",
    "* 3x3 convolution with 16 filters, padding=1 and _ReLU_ activation\n",
    "* 4x4 pooling\n",
    "* flatten\n",
    "* Linear layer with ~180 input and ~100 output sizes and _ReLU_ activation\n",
    "* output linear layer\n",
    "\n",
    "\n",
    "To find the size of the 1st linear layer you can run the cell below and \n",
    "if it throws error like this: \n",
    "\n",
    "    RuntimeError: size mismatch, m1: [32 x 784], m2: [144 x 100], \n",
    "  \n",
    "you should change the size of the Linear layer to 784.\n",
    "\n",
    "Once you're done (and compute_loss no longer raises errors), train it with __Adam__ optimizer with default params (feel free to modify the `train` procedure above).\n",
    "\n",
    "\n",
    "__HACK_OF_THE_DAY__: the number of channels must be in the order of the number of class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "XRTq8rxPrYFU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e782078c09e89e469fa15e903cc66ac5",
     "grade": false,
     "grade_id": "cell-c99d6ea1d3938f86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        # put all the layer initialization here\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass x through all the layers\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        return x\n",
    "    \n",
    "model2 = Net2().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31NP8etbrYFr"
   },
   "source": [
    "## Train it ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = SummaryWriter('runs/F-MNIST_CNN-redux-6')\n",
    "writer2.add_scalar(\"model/size\", model_count_params(model2))\n",
    "writer2.add_graph(model2, images)\n",
    "writer2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count_params(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model2, writer2, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "B0_7ihSnrYF2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9acc3b7dbb29ab8e8c6db63bae4747c8",
     "grade": true,
     "grade_id": "model2_accuracy",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%time accuracy = test_model(model2, writer2);\n",
    "writer2.close()\n",
    "assert accuracy > 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "seminar_convnets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
