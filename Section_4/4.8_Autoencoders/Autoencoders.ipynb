{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "seed=1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset\n",
    "MNIST dataset will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from markdown import markdown\n",
    "import os\n",
    "\n",
    "print('Run the following command in terminal:')\n",
    "print('tensorboard --logdir runs --bind_all')\n",
    "\n",
    "markdown_string = f\"Tensorboard URL: [https://mlhep.coresearch.club/{os.environ['COCALC_PROJECT_ID']}/server/6006/](https://mlhep.coresearch.club/{os.environ['COCALC_PROJECT_ID']}/server/6006/)\"\n",
    "writer = SummaryWriter('runs/')\n",
    "\n",
    "HTML(\"<p>{}</p>\".format(markdown(markdown_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "\n",
    "mnist_transforms = transforms.Compose([ \n",
    "    transforms.ToTensor(), # PIL Image -> Tensor\n",
    "#     transforms.Lambda(lambda x: x/255.),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../../share', train=True,\n",
    "                   transform=mnist_transforms),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../../share', train=False, transform=mnist_transforms),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "image.shape\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "indx = 0\n",
    "plt.title(f'MNIST: {label[indx].item()}')\n",
    "plt.imshow(image[indx].squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Autoencoder model\n",
    "![](http://bjlkeng.github.io/images/autoencoder_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "054857e83b2df5c441f8930212debd86",
     "grade": false,
     "grade_id": "6404ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, hidden_size=20):\n",
    "        super(AE, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Define self.encoder and self.decoder ()\n",
    "        \n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def encode(self, x):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    def decode(self, z): return self.decoder(z).view(-1,28,28)\n",
    "    def forward(self, x):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    def sample(self, size):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    @property\n",
    "    def device(self): return next(self.parameters()).device\n",
    "\n",
    "\n",
    "model = AE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da51409c47ba65ec62f9bc62419befce",
     "grade": true,
     "grade_id": "eba360",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    data_recon = model(data.to(device))\n",
    "    assert data_recon.shape == torch.Size([128,28,28])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d96b95f1056cce6fc79ade0d3c7e060c",
     "grade": false,
     "grade_id": "0e68e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recon_loss(recon_x, x):\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    return MSE\n",
    "\n",
    "\n",
    "log_interval=10\n",
    "epochs=30\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    writer.add_scalar('ae/train_loss', train_loss, epoch)\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    writer.add_scalar('ae/test_loss', test_loss)\n",
    "    return test_loss\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample_size=64\n",
    "        sample = model.sample(sample_size).cpu()\n",
    "        img = make_grid(sample.view(-1,1,28,28))\n",
    "        writer.add_image('ae/test_image', img, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e994ef59563c1c60c82c198f03425905",
     "grade": true,
     "grade_id": "a31e56",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img.permute((1,2,0))*255).detach().cpu().numpy().astype('uint8').squeeze()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d77564089c0c1e1750f21cc960100505",
     "grade": false,
     "grade_id": "e74702",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = AE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def recon_loss(recon_x, x):\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    return MSE\n",
    "\n",
    "\n",
    "# log_interval=10\n",
    "epochs=30\n",
    "\n",
    "def train(epoch,var=1e-2):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # Add noise to image in training stage with \"var\" variance\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    writer.add_scalar('dae/train_loss', train_loss)\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n",
    "\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    writer.add_scalar('dae/test_loss', test_loss)\n",
    "    return test_loss\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample_size=64\n",
    "        sample = model.sample(sample_size).cpu()\n",
    "        img = make_grid(sample.view(-1,1,28,28))\n",
    "        writer.add_image('dae/test_image', img, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91b7a644d1c362edcc205ea337d04b8f",
     "grade": true,
     "grade_id": "5bf284",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img.permute((1,2,0))*255).detach().cpu().numpy().astype('uint8').squeeze()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Sparse autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df2cf9280ea89e6d521a06c8527513f5",
     "grade": false,
     "grade_id": "bf98a3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement Sparse autoencoder with L1 regularization on each intermediate activation\n",
    "\n",
    "class SparseAE(nn.Module):\n",
    "    def __init__(self, hidden_size=20):\n",
    "        super(SparseAE, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Define self.encoder and self.decoder ()\n",
    "        \n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def encode(self, x):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    def decode(self, z): return self.decoder(z).view(-1,28,28)\n",
    "    def forward(self, x):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    def sample(self, size):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    @property\n",
    "    def device(self): return next(self.parameters()).device\n",
    "\n",
    "model = SparseAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def recon_loss(recon_x, x):\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    return MSE\n",
    "\n",
    "\n",
    "# log_interval=10\n",
    "epochs=30\n",
    "var = 1e-2\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss, train_loss_reg = 0, 0\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_loss_reg /= len(train_loader.dataset)\n",
    "    writer.add_scalar('dae/train_loss', train_loss)\n",
    "    writer.add_scalar('dae/train_loss_reg', train_loss_reg)\n",
    "            \n",
    "    print('====> Epoch: {} Average loss: {:.4f} Reg loss: {:.4f}'.format(epoch, train_loss, train_loss_reg))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss, test_loss_reg = 0, 0\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_loss_reg /= len(test_loader.dataset)\n",
    "    writer.add_scalar('dae/test_loss', test_loss)\n",
    "    return test_loss, test_loss_reg\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test_loss, test_loss_reg = test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample_size=64\n",
    "        sample = model.sample(sample_size).cpu()\n",
    "        img = make_grid(sample.view(-1,1,28,28))\n",
    "        writer.add_image('sae/test_image', img, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6b202d66a6170d35e1531a16a5216e6",
     "grade": true,
     "grade_id": "edd62b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img.permute((1,2,0))*255).detach().cpu().numpy().astype('uint8').squeeze()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Links\n",
    "\n",
    "[Simple explanation of AE](http://bjlkeng.github.io/posts/autoregressive-autoencoders/)\n",
    "\n",
    "[Sparse autoencoder](https://debuggercafe.com/sparse-autoencoders-using-l1-regularization-with-pytorch/)\n",
    "\n",
    "[Denoising autoencoder](https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
