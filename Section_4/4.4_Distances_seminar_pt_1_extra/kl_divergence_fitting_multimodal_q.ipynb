{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pyro\n",
    "import numpy.testing as np_testing\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy.special import expit, logit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set(font_scale=1.5, rc={'figure.figsize':(11.7, 8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro import distributions as distrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Task: Implementing KL Divergance for a discrete distribution\n",
    "\n",
    "$$KL ( P||Q ) = \\int_{R^n}p(x)\\log\\left( \\frac{p(x)}{q_{\\theta}(x)}\\right) dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "\n",
    "def compute_kl_divergence(p_probs: torch.Tensor, q_probs: torch.Tensor):\n",
    "    \"\"\"\"\n",
    "    KL (P || Q) = \\int_{R^n}p(x)\\log\\left( \\frac{p(x)}{q_{\\theta}(x)}\\right) = \n",
    "                = \\sum_i p_i log(p_i / q_i)\n",
    "    \n",
    "    Note:\n",
    "        1. The output -- kl_div -- should be one number that is equal to KL (P || Q)\n",
    "        2. Do not forget to clamp your probabilities to avoid log(0) and (x / 0) problems!\n",
    "    \"\"\"\n",
    "    p_probs, q_probs = p_probs.clamp(min=EPS), q_probs.clamp(min=EPS)\n",
    "    kl_div = (p_probs * (p_probs / q_probs).log()).sum()\n",
    "    return kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Task: Implementing JS Divergance for a discrete distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_js_divergence(p_probs, q_probs):\n",
    "    \"\"\"\"\n",
    "    JS (P || Q) = (KL(P || Q) + KL(Q || P)) / 2\n",
    "    Note:\n",
    "        1. The output should be one number that is equal to KL (P || Q)\n",
    "    \"\"\"\n",
    "    kl_div = compute_kl_divergence(p_probs, q_probs)\n",
    "    rkl_div = compute_kl_divergence(q_probs, p_probs)\n",
    "    return (kl_div + rkl_div) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fitting 2D-normal distribution\n",
    "\n",
    "Credits: my collegues that https://github.com/HSE-LAMBDA/DeepGenerativeModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"\n",
    "    shape: tuple of ints, i.e. (1, 2) or (54, 7, 3)\n",
    "    \n",
    "    Sample from Gumbel(0, 1)\n",
    "    \"\"\"\n",
    "    U = torch.rand(shape)\n",
    "    sample = -(-(U + eps).log() + eps).log()\n",
    "    return sample\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "    \"\"\"\n",
    "    logits: [batch_size, num_distributions]torch.Tensor that represents unnormalized log-probs \n",
    "             of the batch_size categorical distributions\n",
    "    temperature: torch.Tensor scalar, temperature of the Gumbel SoftMax Distribution\n",
    "    \n",
    "    Draw a sample from the Gumbel-Softmax distribution\n",
    "    \"\"\"\n",
    "    y = logits + sample_gumbel(logits.shape).to(logits)\n",
    "    g = torch.softmax(y / temperature, dim=-1)\n",
    "    return g\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    \"\"\"\n",
    "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    \n",
    "    logits: [batch_size, num_distributions] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    \n",
    "    Returns:\n",
    "    [batch_size, num_distributions] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    if hard:\n",
    "        ind = y.argmax(dim=-1)\n",
    "        y_hard = torch.zeros_like(y).view(-1, y.shape[-1])\n",
    "        y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "        y = (y_hard - y).detach() + y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import MultivariateNormal\n",
    "def plot_2d_dots(dots, color='blue', label='None'):\n",
    "    plt.ylim(-10, 10)\n",
    "    plt.xlim(-10, 10)\n",
    "    plt.scatter(dots[:, 0], dots[:, 1], s=1, c=color, label=label)\n",
    "\n",
    "\n",
    "def get_parameters(mu=0., sigma=1.):\n",
    "    train_mu = torch.Tensor([mu, mu]).requires_grad_(True)\n",
    "    train_sigma = torch.Tensor([[sigma, 0.0],\n",
    "                                [0.0, sigma]]).requires_grad_(True)\n",
    "    return train_mu, train_sigma\n",
    "\n",
    "def create_distr(mu, sigma):\n",
    "    return distrs.MultivariateNormal(mu, sigma)\n",
    "\n",
    "\n",
    "def sample(d, num):\n",
    "    return d.sample(torch.Size([num]))\n",
    "\n",
    "class MixtureDistribution:\n",
    "    def __init__(self, p1, p2, w=0.5):\n",
    "        self._p1 = p1\n",
    "        self._p2 = p2\n",
    "        self._w = w\n",
    "        \n",
    "    def sample(self, n):\n",
    "        return torch.cat([sample(self._p1, int(n * self._w)), sample(self._p2, n - int(n * self._w))])\n",
    "    \n",
    "    def log_prob(self, x):\n",
    "        return (EPS + self._w * self._p1.log_prob(x).exp() + (1. - self._w) * self._p2.log_prob(x).exp()).log()\n",
    "\n",
    "\n",
    "class MixtureDistributionWithGumbel:\n",
    "    def __init__(self, ps, w, temp=10.):\n",
    "        self._ps = ps\n",
    "        self._w = w\n",
    "        self._temp = temp\n",
    "        \n",
    "    def sample(self, n):\n",
    "        y = gumbel_softmax(self._w.repeat(n, 1), self._temp, hard=True)\n",
    "        xs = []\n",
    "        for p in self._ps:\n",
    "            xs.append(sample(p, n))\n",
    "        init = torch.zeros_like(xs[0])\n",
    "        for i, x in enumerate(xs):\n",
    "            init = init + x * y[:, i].view(-1, 1)\n",
    "        return init\n",
    "    \n",
    "    def log_prob(self, x):\n",
    "        w = torch.softmax(self._w, 0)\n",
    "        xs = []\n",
    "        for p in self._ps:\n",
    "            xs.append(p.log_prob(x).exp())\n",
    "        init = torch.zeros_like(xs[0])\n",
    "        for i, x in enumerate(xs):\n",
    "            init = init + w[i] * x\n",
    "        return (init + EPS).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Target distribution\n",
    "\n",
    "Target distribution is a mixture of two 2-dimensionals normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Generation\n",
    "\n",
    "Here we sampling training data from real distribution:\n",
    "\n",
    "\n",
    "$$D_{train} = \\{x\\}_{i=1}^{n} \\sim p(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = create_distr(\n",
    "    mu=torch.Tensor([5, -5]), \n",
    "    sigma=torch.Tensor([[1., 0.0], \n",
    "                        [0.0, 1.]])\n",
    ")\n",
    "\n",
    "P2 = create_distr(\n",
    "    mu=torch.Tensor([-4, 6]), \n",
    "    sigma=torch.Tensor([[1., 0.0], \n",
    "                        [0.0, 1.]])\n",
    ")\n",
    "\n",
    "P = MixtureDistribution(P1, P2, 0.5)\n",
    "\n",
    "samples_x = P.sample(1000)\n",
    "px = P.log_prob(samples_x).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mixture_distr(mus, sigmas, w, temp=1.):\n",
    "    ds = []\n",
    "    for mu, sigma in zip(mus, sigmas):\n",
    "        ds.append(\n",
    "            create_distr(\n",
    "                mu=mu, \n",
    "                sigma=torch.diag(torch.nn.functional.softplus(torch.diag(sigma))) + 0.1 # dirty hack 1\n",
    "            )\n",
    "        )\n",
    "                  \n",
    "    return MixtureDistributionWithGumbel(ds, w, temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_1, train_sigma_1 = get_parameters(mu=1, sigma=5)\n",
    "train_mu_2, train_sigma_2 = get_parameters(mu=-1, sigma=5)\n",
    "train_mu_3, train_sigma_3 = get_parameters(mu=-1, sigma=5)\n",
    "w = torch.tensor([0., 0., 0.], requires_grad=True)\n",
    "Q = create_mixture_distr([train_mu_1, train_mu_2, train_mu_3], [train_sigma_1, train_sigma_2, train_sigma_3], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_2d_dots(samples_x, color=px, label='Target distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu, train_sigma = get_parameters()\n",
    "\n",
    "samples_q = Q.sample(1000)\n",
    "plt.figure()\n",
    "plot_2d_dots(samples_x, color='r', label='Target distribution: P(x)')\n",
    "plot_2d_dots(samples_q.detach(), color= Q.log_prob(samples_q).exp().detach(), label='Search distribution: Q(x)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Task: optimization of KL\n",
    "\n",
    "In cases when the only thing you have is the data sampled from real distribution:\n",
    "\n",
    "$$D_{train} = \\{x\\}_{i=1}^{n} \\sim p(x)$$\n",
    "\n",
    "To estimate KL divergance you can apply MC estimation. I.e.\n",
    "\n",
    "\n",
    "$$KL ( P||Q ) = \\int_{R^n}p(x)\\log\\left( \\frac{p(x)}{q_{\\theta}(x)}\\right) dx \\approx \\sum\\limits_{x \\in D} p(x) \\log\\left( \\frac{p(x)}{q(x)} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_kl(samples_x, px, mus, sigmas, w, P):\n",
    "    \"\"\"\n",
    "    Here your task is to estimate KL divergance\n",
    "    \n",
    "    1. Create Q distribution with parameters train_mu and train_sigma\n",
    "    2. Estimate qx on samples from real distribution\n",
    "    3. apply function for KL computation\n",
    "    \"\"\"\n",
    "    Q = create_mixture_distr(mus, sigmas, w)\n",
    "    qx = Q.log_prob(samples_x).exp()\n",
    "    loss = compute_kl_divergence(px, qx)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_1, train_sigma_1 = get_parameters(mu=0, sigma=5)\n",
    "train_mu_1.grad = torch.zeros_like(train_mu_1)\n",
    "train_mu_2, train_sigma_2 = get_parameters(mu=-1, sigma=5)\n",
    "train_mu_3, train_sigma_3 = get_parameters(mu=0, sigma=5)\n",
    "mus = [train_mu_1, train_mu_2, train_mu_3]\n",
    "sigmas = [train_sigma_1, train_sigma_2, train_sigma_3]\n",
    "w = torch.tensor([0.01, 0.02, -0.01], requires_grad=True)\n",
    "Q = create_mixture_distr(mus, sigmas, w)\n",
    "ws = []\n",
    "\n",
    "optim = torch.optim.RMSprop(\n",
    "    [train_mu_1, train_sigma_1, train_mu_2, train_sigma_2, train_mu_3, train_sigma_3, w], \n",
    "    lr=1e-2)\n",
    "\n",
    "for i in range(5000):\n",
    "    # Here your task is to \n",
    "    # 1. create Q distribution with \n",
    "    # 2. calculate p.d.f. of the binomial distribution\n",
    "    # 3. apply func to true_data and p.d.f. from previous step\n",
    "    # 4. perform usual backprop\n",
    "    # Do not forget to zero grad after weights update!\n",
    "\n",
    "    ws.append(torch.softmax(w, 0))\n",
    "    optim.zero_grad()\n",
    "    Q = create_mixture_distr(mus, sigmas, w)\n",
    "\n",
    "    loss = estimate_kl(samples_x, px, mus, sigmas, w, P)\n",
    "    if not (train_mu_1.grad == train_mu_1.grad).all():\n",
    "        print('Failed grad')\n",
    "        continue\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        # plot pdfs\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(f'KL={loss.item()}, iter={i}')\n",
    "        plot_2d_dots(samples_x, color='r', label='Target distribution: P(x)')\n",
    "        samples_q = Q.sample(1000)\n",
    "        plot_2d_dots(samples_q.detach(), color= Q.log_prob(samples_q).exp().detach(), label='Search distribution: Q(x)')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_1, train_sigma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_2, train_sigma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_3, train_sigma_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.stack(ws)[:, 0].detach(), label='Mixture weight 1')\n",
    "plt.plot(torch.stack(ws)[:, 1].detach(), label='Mixture weight 2')\n",
    "plt.plot(torch.stack(ws)[:, 2].detach(), label='Mixture weight 2')\n",
    "plt.title(\"Training with KL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: \n",
    "\n",
    "The search distribution should look like its trying to cover both modes of the target distribution. Like in the lecture :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Task: optimization of rKL\n",
    "\n",
    "###### Here you will understand: \n",
    "    - the hidden power of Pyro\n",
    "    - what is wrong with rKL\n",
    "    \n",
    "    \n",
    "    \n",
    "To estimate rKL divergance you can apply MC estimation. I.e.\n",
    "\n",
    "\n",
    "$$KL ( P||Q ) = \\int_{R^n} q_{\\theta}(x) \\log\\left( \\frac{q_{\\theta}(x)}{p(x)}\\right) dx \\approx \\sum\\limits_{x \\in q(x)} q_{\\theta}(x) \\log\\left( \\frac{q_{\\theta}(x)}{p(x)} \\right)$$\n",
    "\n",
    "###### Note that here we are averaging over samples from q(x)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(d, num):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    res = pyro.sample(\"dist\", d.expand([num]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_reverse_kl(samples_x, mus, sigmas, w, P, n_samples=2000):\n",
    "    \"\"\"\n",
    "    Here your task is to estimate rKL divergance\n",
    "    \n",
    "    1. Create Q distribution with parameters train_mu and train_sigma\n",
    "    2. Sample(!) points x_q from Q distribution\n",
    "    3. Estimate p(x_q)\n",
    "    4. Estimate q(x_q)\n",
    "    3. apply function for KL computation\n",
    "    \"\"\"\n",
    "    Q = create_mixture_distr(mus, sigmas, w)\n",
    "    q = Q.sample(n_samples)\n",
    "    px = P.log_prob(q).exp()\n",
    "    qx = Q.log_prob(q).exp()\n",
    "    loss = compute_kl_divergence(qx, px)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_1, train_sigma_1 = get_parameters(mu=0, sigma=5)\n",
    "train_mu_1.grad = torch.zeros_like(train_mu_1)\n",
    "train_mu_2, train_sigma_2 = get_parameters(mu=-1, sigma=5)\n",
    "train_mu_3, train_sigma_3 = get_parameters(mu=0, sigma=5)\n",
    "mus = [train_mu_1, train_mu_2, train_mu_3]\n",
    "sigmas = [train_sigma_1, train_sigma_2, train_sigma_3]\n",
    "w = torch.tensor([0.01, 0.02, -0.01], requires_grad=True)\n",
    "Q = create_mixture_distr(mus, sigmas, w)\n",
    "ws = []\n",
    "\n",
    "optim = torch.optim.RMSprop(\n",
    "    [train_mu_1, train_sigma_1, train_mu_2, train_sigma_2, train_mu_3, train_sigma_3, w], \n",
    "    lr=1e-2)\n",
    "\n",
    "\n",
    "for i in range(5000):\n",
    "    ws.append(torch.softmax(w, 0))\n",
    "    optim.zero_grad()\n",
    "    Q = create_mixture_distr(mus, sigmas, w)\n",
    "    loss = estimate_reverse_kl(samples_x, mus, sigmas, w, P)\n",
    "    loss.backward()\n",
    "    if not (train_mu_1.grad == train_mu_1.grad).all():\n",
    "        print('Failed grad')\n",
    "        continue\n",
    "    optim.step()\n",
    "    if i % 200 == 0:\n",
    "        # plot pdfs\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(f'KL={loss.item()}, iter={i}')\n",
    "        plot_2d_dots(samples_x, color='r', label='Target distribution: P(x)')\n",
    "        samples_q = Q.sample(1000)\n",
    "        plot_2d_dots(samples_q.detach(), color=Q.log_prob(samples_q).exp().detach(), label='Search distribution: Q(x)')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_1, train_sigma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_2, train_sigma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mu_3, train_sigma_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.stack(ws)[:, 0].detach(), label='Mixture weight 1')\n",
    "plt.plot(torch.stack(ws)[:, 1].detach(), label='Mixture weight 2')\n",
    "plt.plot(torch.stack(ws)[:, 2].detach(), label='Mixture weight 2')\n",
    "plt.title(\"Training with rKL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
