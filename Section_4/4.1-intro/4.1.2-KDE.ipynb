{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The tutorial part is based on the scikit-learn [tutorial](https://scikit-learn.org/stable/auto_examples/neighbors/plot_digits_kde_sampling.html#sphx-glr-auto-examples-neighbors-plot-digits-kde-sampling-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mixture of two Gaussians\n",
    "np.random.seed(1242314)\n",
    "N = 2000\n",
    "first_mode = norm(0, 1)\n",
    "second_mode = norm(5, 2)\n",
    "data = np.concatenate([first_mode.rvs(N), second_mode.rvs(N)]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the probability densities for different values of bandwidth\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-5, 15, num=1000).reshape(-1, 1)\n",
    "for bandwidth in (0.1, 1, 3):\n",
    "    estimator = KernelDensity(bandwidth=bandwidth).fit(data)\n",
    "    predictions = estimator.score_samples(x)\n",
    "    print(f\"Bandwidth {bandwidth}; mean test log-likelihood {predictions.mean():.3}\")\n",
    "    # Predictions are log(p(x))\n",
    "    probabilities = np.exp(predictions)\n",
    "    ax.plot(x, probabilities, label=f\"Bandwidth={bandwidth}\")\n",
    "ax.plot(x, 0.5*(first_mode.pdf(x.flatten()) + second_mode.pdf(x.flatten())), label=\"Groud truth\")\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"Probability density\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search and cross-validation to optimize the bandwidth\n",
    "params = {'bandwidth': np.logspace(-1, 1, 20)}\n",
    "grid = GridSearchCV(KernelDensity(), params, cv=4, n_jobs=2)\n",
    "grid.fit(data)\n",
    "optimal_kde = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimal estimator\n",
    "fig, ax = plt.subplots()\n",
    "probabilities = np.exp(optimal_kde.score_samples(x))\n",
    "ax.plot(x, probabilities, label=f\"Bandwidth={optimal_kde.get_params()['bandwidth']:.3f}\")\n",
    "ax.plot(x, 0.5*(first_mode.pdf(x.flatten()) + second_mode.pdf(x.flatten())), label=\"Groud truth\")\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"Probability density\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits data. It's almost like MNIST -- but a lot simplier for the simplier model\n",
    "digits = load_digits()\n",
    "\n",
    "# Project the 64-dimensional data to a lower dimension\n",
    "pca = PCA(n_components=15, whiten=False)\n",
    "data = pca.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search cross-validation to optimize the bandwidth\n",
    "params = {'bandwidth': np.logspace(-1, 1, 20)}\n",
    "grid = GridSearchCV(KernelDensity(), params)\n",
    "grid.fit(data)\n",
    "optimal_kde = grid.best_estimator_\n",
    "\n",
    "print(\"best bandwidth: {0}\".format(grid.best_estimator_.bandwidth))\n",
    "\n",
    "# Use the best estimator to compute the kernel density estimate\n",
    "kde = grid.best_estimator_\n",
    "\n",
    "# Sample 44 new points from the data\n",
    "new_data = kde.sample(44, random_state=0)\n",
    "new_data = pca.inverse_transform(new_data)\n",
    "\n",
    "# Turn data into a 4x11 grid\n",
    "new_data = new_data.reshape((4, 11, -1))\n",
    "real_data = digits.data[:44].reshape((4, 11, -1))\n",
    "\n",
    "# Plot the real digits and the sampled digits\n",
    "fig, ax = plt.subplots(9, 11, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for j in range(11):\n",
    "    ax[4, j].set_visible(False)\n",
    "    for i in range(4):\n",
    "        im = ax[i, j].imshow(real_data[i, j].reshape((8, 8)),\n",
    "                             cmap=plt.cm.binary, interpolation='nearest')\n",
    "        im.set_clim(0, 16)\n",
    "        im = ax[i + 5, j].imshow(new_data[i, j].reshape((8, 8)),\n",
    "                                 cmap=plt.cm.binary, interpolation='nearest')\n",
    "        im.set_clim(0, 16)\n",
    "\n",
    "ax[0, 5].set_title('Selection from the input data')\n",
    "ax[5, 5].set_title('\"New\" digits drawn from the kernel density model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1\n",
    "Plot the optimal bandwidth for the combination of two Gaussians as a function of the training dataset size for training dataset size in `np.linspace(10, 5000, num=10)`. Use `generate_sample` for generating the training data. Given that it is possible to generate an infinite amount of data, it is possible to find the answer with arbitrary precision. For the purpose of this task it is enough to evaluate the performance with bandwidth in ` np.logspace(-1, 1, 20)` on 4-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_mode = norm(0, 1)\n",
    "second_mode = norm(5, 2)\n",
    "def generate_sample(sample_size:int):\n",
    "    \"\"\"\n",
    "    Produces a toy dataset\n",
    "    Args:\n",
    "        sample_size:int -- the desired sample size\n",
    "    Returns:\n",
    "        np.array(sample_size, 1) -- a toy dataset with single feature and sample_size examples\n",
    "    \"\"\"\n",
    "    half_size = sample_size // 2\n",
    "    # In the case of an odd sample size\n",
    "    second_half_size = sample_size - half_size\n",
    "    return np.concatenate([first_mode.rvs(half_size), second_mode.rvs(second_half_size)]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5072fad3783879b738e2e29988fd0575",
     "grade": false,
     "grade_id": "5078e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sizes = np.linspace(10, 5000, num=10, dtype=np.uint32)\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e27c9887c27a3b3206656924cbaec",
     "grade": false,
     "grade_id": "61e3d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 2\n",
    "Use your creativity, physical intuition, knowledge of statistics and ability to read the [KernelDensity documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html) to find the  optimal kernel density parameters for training dataset size=134. Use `generate_sample` for generating as much training and testing data as you desire. Note: 134 is a low number, so make sure your solution is not overfitted to a single training sample. The goal is to have the mean log-likelihood on a test sample drawn from the same distribution > -2.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_params = <your params>\n",
    "# E.g. optimal_params = {\"bandwidth\": 2., \"kernel\": \"epanechnikov\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are many cells below due to the structure of our solution and testing. You can use any number of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c31a76a19c41b9e0c50826dab290b48",
     "grade": false,
     "grade_id": "417c9e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8c5cc477aba82cc85a140e5b28b837d",
     "grade": false,
     "grade_id": "38f626",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb5d02ebbd067c9d7e81e1b7e9ad3f7a",
     "grade": false,
     "grade_id": "377917",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2e1400659e74f242c18ae5185e12e30",
     "grade": false,
     "grade_id": "bd1358",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed8856f1e5713cb747f0f75bc24069fe",
     "grade": false,
     "grade_id": "3fbbff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a566a0e6620fb5b6a5eb44403f7ef230",
     "grade": false,
     "grade_id": "28f724",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b95576c0657dd2e939ed8fc69c46fd5c",
     "grade": true,
     "grade_id": "f7a8b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN TEST\n",
    "# copy-paste to avoid dependece between the solution and the evaluation\n",
    "N_SAMPLES = 134\n",
    "TEST_SIZE = 1000\n",
    "def evaluate_params(params, n_trials):\n",
    "    all_scores = []\n",
    "    for trial in range(n_trials):\n",
    "        train_set = generate_sample(N_SAMPLES)\n",
    "        estimator = KernelDensity(**params).fit(train_set)\n",
    "        scores = estimator.score_samples(generate_sample(TEST_SIZE))\n",
    "        trial_result = scores.mean()\n",
    "        if not(np.isfinite(trial_result)):\n",
    "            return trial_result\n",
    "        all_scores.append(trial_result)\n",
    "    return np.mean(all_scores)\n",
    "### HIDDEN TEST\n",
    "\n",
    "# evaluate_params is implemented in the hidden part of this cell. It's not available, as it would make the task too easy\n",
    "score = evaluate_params(optimal_params, n_trials=1000)\n",
    "assert score > -2.37"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
