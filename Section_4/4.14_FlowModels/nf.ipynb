{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Code is taken from https://github.com/karpathy/pytorch-normalizing-flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.distributions import MultivariateNormal, Uniform, TransformedDistribution, SigmoidTransform\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import sys; sys.path.append('../../../share/data/')\n",
    "\n",
    "from nflib.flows import (\n",
    "    AffineConstantFlow, ActNorm, AffineHalfFlow,\n",
    "    SlowMAF, MAF, IAF, Invertible1x1Conv,\n",
    "    NormalizingFlow, NormalizingFlowModel,\n",
    ")\n",
    "from nflib.spline_flows import NSF_AR, NSF_CL\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Intro\n",
    "**Problem:** how to estimate the pdf of final distribution at each point?\n",
    "\n",
    "\n",
    "**Idea:** Let's define the bijection $z_k=f(z_0)$ between simple distribution of $z_0$ with known pdf and our distribution $z_k$ with unknown pdf\n",
    "\n",
    "\n",
    "![](https://2.bp.blogspot.com/-g37e2x1miRo/Wl-g8ajU11I/AAAAAAAAHkY/PbIorxOav_Y61yFJeXsQLRlcKTzlkykYwCLcBGAs/s1600/shakir_danilo_slide.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Problem:** ... but known pdf is changed at each point after each transformation $f$\n",
    "\n",
    "![](https://2.bp.blogspot.com/-1vyL7LpM1io/Wl-ghB0yOiI/AAAAAAAAHkM/_U94kuVeQpk22J5Mg0lbLK-EdMDkaQWggCLcBGAs/s1600/flow1.png)\n",
    "\n",
    "**Solution:** The Jacobian is exactly the factor how volume is changed at each point $$J_k=|\\frac{\\partial f_k}{\\partial z_k}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### We can stack multiple transformations f\n",
    "\n",
    "<!-- ![](https://lilianweng.github.io/lil-log/assets/images/normalizing-flow.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Thus, the final pdf of our distribution can be evaluated as \n",
    "\n",
    "$$p(z_k)=\\frac{p(z_0)}{\\Pi_{i=1}^k J_i}$$\n",
    "\n",
    "or, \n",
    "\n",
    "$$log(p(z_k))=log(p(z_0))-\\Sigma_{i=1}^klog(J_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example of transformations\n",
    "- Planar flows; $f(x) = x + u h(w^\\intercal z + b)$\n",
    "- Radial flows; $f(x) = x + \\frac{\\beta}{\\alpha + |x - x_0|}(x - x_0)$\n",
    "- Real NVP; affine coupling layer; $f(x^{(2)}) = t(x^{(1)}) + x^{(2)}\\odot\\exp s(x^{(1)}) $\n",
    "- Masked Autoregressive Flow (MAF); $f(x_i) = (x_i - \\mu(x_{<i})) / \\exp(\\alpha(x_{<i}))$\n",
    "- Invertible 1x1 Convolution (Glow);\n",
    "- ActNorm; $f(x) = Wx + b$ where $W$ is diagonal and $b$ is a constant\n",
    "- Autoregressive Neural Spline Flow (NSF-AF); $f(x_i) = \\mathrm{RQS}_{\\theta(x_{<i})}(x_i)$\n",
    "- Coupling Neural Spline Flow (NSF-CL); $f(x^{(2)}) = \\mathrm{RQS}_{\\theta(x^{(1)})}(x^{(2)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example\n",
    "![](http://akosiorek.github.io/resources/simple_flows.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0a1af5bfb50d9732daa73563513a64c",
     "grade": false,
     "grade_id": "e40c10",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Lightweight datasets\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "\n",
    "class DatasetSIGGRAPH:\n",
    "    \"\"\" \n",
    "    haha, found from Eric https://blog.evjang.com/2018/01/nf2.html\n",
    "    https://github.com/ericjang/normalizing-flows-tutorial/blob/master/siggraph.pkl\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        with open('siggraph.pkl', 'rb') as f:\n",
    "            XY = np.array(pickle.load(f), dtype=np.float32)\n",
    "            XY -= np.mean(XY, axis=0) # center\n",
    "        self.XY = torch.from_numpy(XY)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        X = self.XY[np.random.randint(self.XY.shape[0], size=n)]\n",
    "        return X\n",
    "\n",
    "class DatasetMoons:\n",
    "    \"\"\" two half-moons \"\"\"\n",
    "    def sample(self, n):\n",
    "        moons = datasets.make_moons(n_samples=n, noise=0.05)[0].astype(np.float32)\n",
    "        return torch.from_numpy(moons)\n",
    "\n",
    "class DatasetMixture:\n",
    "    \"\"\" 4 mixture of gaussians \"\"\"\n",
    "    def sample(self, n):\n",
    "        assert n%4 == 0\n",
    "        r = np.r_[np.random.randn(n // 4, 2)*0.5 + np.array([0, -2]),\n",
    "                  np.random.randn(n // 4, 2)*0.5 + np.array([0, 0]),\n",
    "                  np.random.randn(n // 4, 2)*0.5 + np.array([2, 2]),\n",
    "                  np.random.randn(n // 4, 2)*0.5 + np.array([-2, 2])]\n",
    "        return torch.from_numpy(r.astype(np.float32))\n",
    "\n",
    "d = DatasetMoons()\n",
    "# d = DatasetMixture()\n",
    "#d = DatasetSIGGRAPH()\n",
    "\n",
    "# sample x using d\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(x[:,0], x[:,1], s=5, alpha=0.5)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32716789c8b697f1e4b59769ef79362e",
     "grade": true,
     "grade_id": "8f5d00",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "assert_equal(x.shape, (128,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a model\n",
    "prior = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "# prior = TransformedDistribution(Uniform(torch.zeros(2), torch.ones(2)), SigmoidTransform().inv) # Logistic distribution\n",
    "\n",
    "# RealNVP\n",
    "flows = [AffineHalfFlow(dim=2, parity=i%2) for i in range(9)]\n",
    "\n",
    "# NICE\n",
    "# flows = [AffineHalfFlow(dim=2, parity=i%2, scale=False) for i in range(4)]\n",
    "# flows.append(AffineConstantFlow(dim=2, shift=False))\n",
    "\n",
    "# SlowMAF (MAF, but without any parameter sharing for each dimension's scale/shift)\n",
    "# flows = [SlowMAF(dim=2, parity=i%2) for i in range(4)]\n",
    "\n",
    "# MAF (with MADE net, so we get very fast density estimation)\n",
    "# flows = [MAF(dim=2, parity=i%2) for i in range(4)]\n",
    "\n",
    "# IAF (with MADE net, so we get very fast sampling)\n",
    "# flows = [IAF(dim=2, parity=i%2) for i in range(3)]\n",
    "\n",
    "# insert ActNorms to any of the flows above\n",
    "# norms = [ActNorm(dim=2) for _ in flows]\n",
    "# flows = list(itertools.chain(*zip(norms, flows)))\n",
    "\n",
    "# Glow paper\n",
    "# flows = [Invertible1x1Conv(dim=2) for i in range(3)]\n",
    "# norms = [ActNorm(dim=2) for _ in flows]\n",
    "# couplings = [AffineHalfFlow(dim=2, parity=i%2, nh=32) for i in range(len(flows))]\n",
    "# flows = list(itertools.chain(*zip(norms, flows, couplings))) # append a coupling layer after each 1x1\n",
    "\n",
    "# Neural splines, coupling\n",
    "# nfs_flow = NSF_CL if True else NSF_AR\n",
    "# flows = [nfs_flow(dim=2, K=8, B=3, hidden_dim=16) for _ in range(3)]\n",
    "# convs = [Invertible1x1Conv(dim=2) for _ in flows]\n",
    "norms = [ActNorm(dim=2) for _ in flows]\n",
    "# flows = list(itertools.chain(*zip(norms, convs, flows)))\n",
    "flows = list(itertools.chain(*zip(norms, flows)))\n",
    "\n",
    "# construct the model\n",
    "model = NormalizingFlowModel(prior, flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) # todo tune WD\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6720a69b0625e061dfe4d65f83f3e493",
     "grade": false,
     "grade_id": "1f0c25",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for k in range(1000):\n",
    "    # sample x\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    zs, prior_logprob, log_det = model(x)\n",
    "    logprob = prior_logprob + log_det\n",
    "    # define loss = NLL (negative log likelihood)\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # gradient step\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "\n",
    "    if k % 100 == 0:\n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c492e9feb6984462c521910f39c24b51",
     "grade": true,
     "grade_id": "7cea08",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert loss.item() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "\n",
    "x = d.sample(128)\n",
    "zs, prior_logprob, log_det = model(x)\n",
    "z = zs[-1]\n",
    "\n",
    "x = x.detach().numpy()\n",
    "z = z.detach().numpy()\n",
    "p = model.prior.sample([128, 2]).squeeze()\n",
    "plt.subplot(131)\n",
    "plt.scatter(p[:,0], p[:,1], c='g', s=5)\n",
    "plt.scatter(z[:,0], z[:,1], c='r', s=5)\n",
    "plt.legend(['prior', 'x->z', 'data'])\n",
    "plt.axis('scaled')\n",
    "plt.title('x -> z')\n",
    "\n",
    "zs = model.sample(128*8)\n",
    "z = zs[-1]\n",
    "z = z.detach().numpy()\n",
    "plt.subplot(132)\n",
    "plt.scatter(x[:,0], x[:,1], c='b', s=5, alpha=0.5)\n",
    "plt.scatter(z[:,0], z[:,1], c='r', s=5, alpha=0.5)\n",
    "plt.legend(['data', 'z->x'])\n",
    "plt.axis('scaled')\n",
    "plt.title('z -> x')\n",
    "\n",
    "plt.subplot(133)\n",
    "ng = 100\n",
    "xx, yy = np.linspace(-3, 3, ng), np.linspace(-3, 3, ng)\n",
    "xv, yv = np.meshgrid(xx, yy)\n",
    "xy = np.stack([xv, yv], axis=-1)\n",
    "xy = xy.reshape((ng*ng, 2))\n",
    "xy = torch.from_numpy(xy).float()\n",
    "zs, prior_logprob, log_det = model(xy)\n",
    "plt.scatter(xy[:,0], xy[:,1], c=np.nan_to_num(prior_logprob.detach().exp()))\n",
    "plt.title('density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the step-wise flow in the full net\n",
    "from matplotlib import collections  as mc\n",
    "\n",
    "# plot the coordinate warp\n",
    "ng = 20\n",
    "xx, yy = np.linspace(-3, 3, ng), np.linspace(-3, 3, ng)\n",
    "xv, yv = np.meshgrid(xx, yy)\n",
    "xy = np.stack([xv, yv], axis=-1)\n",
    "in_circle = np.sqrt((xy**2).sum(axis=2)) <= 3 # seems appropriate since we use radial distributions as priors\n",
    "xy = xy.reshape((ng*ng, 2))\n",
    "xy = torch.from_numpy(xy.astype(np.float32))\n",
    "\n",
    "zs, log_det = model.backward(xy)\n",
    "\n",
    "backward_flow_names = [type(f).__name__ for f in model.flow.flows[::-1]]\n",
    "nz = len(zs)\n",
    "for i in range(nz - 1):\n",
    "    z0 = zs[i].detach().numpy()\n",
    "    z1 = zs[i+1].detach().numpy()\n",
    "    \n",
    "    # plot how the samples travel at this stage\n",
    "    figs, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    axs[0].scatter(z0[:,0], z0[:, 1], c='r', s=3)\n",
    "    axs[0].scatter(z1[:,0], z1[:, 1], c='b', s=3)\n",
    "    axs[0].quiver(z0[:,0], z0[:,1], z1[:,0] - z0[:,0], z1[:,1] - z0[:,1], units='xy', scale=1, alpha=0.5)\n",
    "    axs[0].axis([-3, 3, -3, 3])\n",
    "    axs[0].set_title(\"layer %d -> %d (%s)\" % (i, i+1, backward_flow_names[i]))\n",
    "    \n",
    "    q = z1.reshape((ng, ng, 2))\n",
    "    # y coords\n",
    "    p1 = np.reshape(q[1:,:,:], (ng**2-ng,2))\n",
    "    p2 = np.reshape(q[:-1,:,:], (ng**2-ng,2))\n",
    "    inc = np.reshape(in_circle[1:,:] | in_circle[:-1,:], (ng**2-ng,))\n",
    "    p1, p2 = p1[inc], p2[inc]\n",
    "    lcy = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "    # x coords\n",
    "    p1 = np.reshape(q[:,1:,:], (ng**2-ng,2))\n",
    "    p2 = np.reshape(q[:,:-1,:], (ng**2-ng,2))\n",
    "    inc = np.reshape(in_circle[:,1:] | in_circle[:,:-1], (ng**2-ng,))\n",
    "    p1, p2 = p1[inc], p2[inc]\n",
    "    lcx = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "    # draw the lines\n",
    "    axs[1].add_collection(lcy)\n",
    "    axs[1].add_collection(lcx)\n",
    "    axs[1].axis([-3, 3, -3, 3])\n",
    "    axs[1].set_title(\"grid warp at the end of %d\" % (i+1,))\n",
    "    \n",
    "    # draw the data too\n",
    "    plt.scatter(x[:,0], x[:,1], c='r', s=5, alpha=0.5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train and render\n",
    "# code duplication because it's very late at night now and i'm tired\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "ng = 20\n",
    "xx, yy = np.linspace(-3, 3, ng), np.linspace(-3, 3, ng)\n",
    "xv, yv = np.meshgrid(xx, yy)\n",
    "xy = np.stack([xv, yv], axis=-1)\n",
    "in_circle = np.sqrt((xy**2).sum(axis=2)) <= 3\n",
    "xy = xy.reshape((ng*ng, 2))\n",
    "xy = torch.from_numpy(xy.astype(np.float32))\n",
    "\n",
    "xval = d.sample(128*5)\n",
    "\n",
    "model.train()\n",
    "for k in range(500):\n",
    "    \n",
    "    # sample\n",
    "    x = d.sample(128)\n",
    "    \n",
    "    # train a bit\n",
    "    zs, prior_logprob, log_det = model(x)\n",
    "    logprob = prior_logprob + log_det\n",
    "    loss = -torch.sum(logprob) # NLL\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if k % 10 == 0:\n",
    "        # vis\n",
    "        zs, log_det = model.backward(xy)\n",
    "        backward_flow_names = [type(f).__name__ for f in model.flow.flows[::-1]]\n",
    "        nz = len(zs)\n",
    "        i = nz - 1 - 1\n",
    "\n",
    "        z0 = zs[i].detach().numpy()\n",
    "        z1 = zs[i+1].detach().numpy()\n",
    "\n",
    "        # plot how the samples travel at this stage\n",
    "        ss = 0.1\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        outer = gridspec.GridSpec(1, 2, wspace=ss, hspace=ss)\n",
    "        inner1 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=outer[0], wspace=ss, hspace=ss)\n",
    "        inner2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=outer[1], wspace=ss, hspace=ss)\n",
    "        \n",
    "        backward_flow_names = [type(f).__name__ for f in model.flow.flows[::-1]]\n",
    "        nz = len(zs)\n",
    "        for i in range(min(nz-1, 9)):\n",
    "            ax = plt.Subplot(fig, inner1[i])\n",
    "            z0 = zs[i].detach().numpy()\n",
    "            z1 = zs[i+1].detach().numpy()\n",
    "            ax.scatter(z0[:,0], z0[:, 1], c='r', s=1, alpha=0.5)\n",
    "            ax.scatter(z1[:,0], z1[:, 1], c='b', s=1, alpha=0.5)\n",
    "            ax.quiver(z0[:,0], z0[:,1], z1[:,0] - z0[:,0], z1[:,1] - z0[:,1], units='xy', scale=1, alpha=0.5)\n",
    "            ax.axis([-3, 3, -3, 3])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "            #ax.set_title(\"layer %d -> %d (%s)\" % (i, i+1, backward_flow_names[i]))\n",
    "            fig.add_subplot(ax)\n",
    "        \n",
    "        ax = plt.Subplot(fig, inner2[0])\n",
    "        q = z1.reshape((ng, ng, 2))\n",
    "        # y coords\n",
    "        p1 = np.reshape(q[1:,:,:], (ng**2-ng,2))\n",
    "        p2 = np.reshape(q[:-1,:,:], (ng**2-ng,2))\n",
    "        inc = np.reshape(in_circle[1:,:] | in_circle[:-1,:], (ng**2-ng,))\n",
    "        p1, p2 = p1[inc], p2[inc]\n",
    "        lcy = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "        # x coords\n",
    "        p1 = np.reshape(q[:,1:,:], (ng**2-ng,2))\n",
    "        p2 = np.reshape(q[:,:-1,:], (ng**2-ng,2))\n",
    "        inc = np.reshape(in_circle[:,1:] | in_circle[:,:-1], (ng**2-ng,))\n",
    "        p1, p2 = p1[inc], p2[inc]\n",
    "        lcx = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "        # draw the lines\n",
    "        ax.add_collection(lcy)\n",
    "        ax.add_collection(lcx)\n",
    "        ax.axis([-3, 3, -3, 3])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        #ax.set_title(\"grid warp at the end of %d\" % (i+1,))\n",
    "        fig.add_subplot(ax)\n",
    "        \n",
    "        # draw the data too\n",
    "        plt.scatter(xval[:,0], xval[:,1], c='r', s=5, alpha=0.5)\n",
    "        \n",
    "        break\n",
    "        #fname = 'out/step_%04d.png' % (k,)\n",
    "        #plt.savefig(fname, dpi=200)\n",
    "        #print(\"saved\", fname, 'loss', loss.item())\n",
    "        #plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
