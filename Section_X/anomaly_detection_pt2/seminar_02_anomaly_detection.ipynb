{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import numpy.testing as np_testing\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set(font_scale=1.5, rc={'figure.figsize':(11.7, 8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting functions, nothing to do here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_level_lines(model, data, labels, size=100):\n",
    "    def _expand(a, b, frac=.5, margin=1.):\n",
    "        return a - abs(a) * frac - margin, b + abs(b) * frac + margin\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    min_x, min_y = data.min(axis=0)\n",
    "    max_x, max_y = data.max(axis=0)\n",
    "    min_x, max_x = _expand(min_x, max_x)\n",
    "    min_y, max_y = _expand(min_y, max_y)\n",
    "\n",
    "    all_x = np.linspace(min_x, max_x, num=size)\n",
    "    all_y = np.linspace(min_y, max_y, num=size)\n",
    "    XX, YY = np.meshgrid(all_x, all_y)\n",
    "    test_data = np.c_[XX.ravel(), YY.ravel()]\n",
    "\n",
    "    try:\n",
    "        predictions = model.decision_function(test_data).reshape(size, size)\n",
    "        data_scores = model.predict(data)\n",
    "        anomaly_scores = model.decision_function(data)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            predictions = model._decision_function(test_data).reshape(size, size)\n",
    "            data_scores = model._predict(data)\n",
    "            anomaly_scores = model._decision_function(data)\n",
    "        except AttributeError:\n",
    "            predictions = model.predict_proba(test_data)[:, 0].reshape(size, size)\n",
    "            data_scores = model.predict(data)\n",
    "            anomaly_scores = model.predict_proba(data)[:, 0]\n",
    "\n",
    "    plt.contourf(all_x, all_y, predictions, cmap=plt.cm.coolwarm)\n",
    "\n",
    "    threshold = anomaly_scores[data_scores==1.0].min()\n",
    "    plt.contour(XX, YY, predictions, levels=[threshold], linewidths=2, colors='darkred')\n",
    "\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([min_x,max_x])\n",
    "    axes.set_ylim([min_y,max_y])\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "\n",
    "def plot_results(y_test, probabilities):\n",
    "    # plot ROC and PR curves\n",
    "    fpr, tpr, _ = roc_curve(y_test, probabilities)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probabilities)\n",
    "\n",
    "    fig, (ax_roc, ax_pr_rec) = plt.subplots(nrows=1, ncols=2)\n",
    "    fig.set_size_inches(15, 5)\n",
    "\n",
    "    # roc\n",
    "    ax_roc.plot(fpr, tpr, linewidth=3)\n",
    "    ax_roc.set_xlabel('FPR')\n",
    "    ax_roc.set_ylabel('TPR')\n",
    "\n",
    "    ax_roc.grid(True)\n",
    "    ax_roc.xaxis.label.set_fontsize(20)\n",
    "    ax_roc.yaxis.label.set_fontsize(20)\n",
    "\n",
    "    ax_roc.fill_between(fpr, tpr, 0, alpha=0.1)\n",
    "\n",
    "    # precision-recall\n",
    "    ax_pr_rec.plot(recall, precision, linewidth=3)\n",
    "    ax_pr_rec.set_xlabel('Recall')\n",
    "    ax_pr_rec.set_ylabel('Precision')\n",
    "\n",
    "    ax_pr_rec.grid(True)\n",
    "    ax_pr_rec.xaxis.label.set_fontsize(20)\n",
    "    ax_pr_rec.yaxis.label.set_fontsize(20)\n",
    "\n",
    "    ax_pr_rec.fill_between(recall, precision, 0, alpha=0.1)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Anomaly detection with VAE\n",
    "\n",
    "![](https://habrastorage.org/web/725/94b/5de/72594b5de85e4e58a0ae071bf2ab2ca7.png)\n",
    "\n",
    "![](https://habrastorage.org/web/a4e/ec5/3a3/a4eec53a3cf24b289e494e4f03f71a39.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Toy data generation\n",
    "\n",
    "Let's generate some moons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_moons(train_size_pos=64, train_size_neg=4, test_size=64):\n",
    "    from sklearn.datasets import make_moons\n",
    "\n",
    "    get_pos = lambda size, seed: make_moons(n_samples=size, noise=0.05, random_state=seed)[0].astype('float32')\n",
    "\n",
    "    data_pos = get_pos(train_size_pos, random_seed)\n",
    "    data_pos_test = get_pos(test_size, random_seed + 2)\n",
    "\n",
    "    center = np.array([0.5, 0.25], dtype='float32')\n",
    "    X_range = np.array([\n",
    "      [-1.25, 2.25],\n",
    "      [-0.75, 1.25],\n",
    "    ], dtype='float32')\n",
    "\n",
    "    np.random.seed(random_seed + 3)\n",
    "    \n",
    "    def get_neg(n):\n",
    "        length = np.sqrt(np.random.uniform(1., 4., size=n))\n",
    "        angle = np.pi * np.random.uniform(0, 2, size=n)\n",
    "        x = length * np.cos(angle)\n",
    "        y = length * np.sin(angle)\n",
    "        return np.vstack((x, y)).T + center\n",
    "    \n",
    "    data_neg = get_neg(train_size_neg)\n",
    "    data_neg_test = get_neg(test_size)\n",
    "\n",
    "    data_train = np.concatenate([\n",
    "      data_pos,\n",
    "      data_neg\n",
    "    ], axis=0)\n",
    "    \n",
    "    data_test = np.concatenate([\n",
    "      data_pos_test,\n",
    "      data_neg_test\n",
    "    ], axis=0)\n",
    "\n",
    "    labels_train = np.concatenate([\n",
    "      np.ones(data_pos.shape[0], dtype='float32'),\n",
    "      np.zeros(data_neg.shape[0], dtype='float32')\n",
    "    ])\n",
    "    labels_test = np.concatenate([\n",
    "      np.ones(data_pos_test.shape[0], dtype='float32'),\n",
    "      np.zeros(data_neg_test.shape[0], dtype='float32')\n",
    "    ])\n",
    "    return data_train, labels_train, data_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = create_dataset_moons(\n",
    "    train_size_pos=1024, train_size_neg=16, test_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X_train.T, c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection problem statement: train function $\\hat{f}:\\mathcal{X}\\to \\mathbb{R}$ on dataset $\\mathcal{S}$, such that\n",
    "\n",
    "  * $\\hat{f}(x) \\leq 0$, where $x$ -- **normal** observation, $\\hat{f}(x) > 0$ -- **anomal**;\n",
    "\n",
    "  * with low rate of **misses**: $\\hat{f}(x) \\leq 0$ for **anomal** $x$;\n",
    "\n",
    "  * and low rate of **false alarms**: $\\hat{f}(x) > 0$ for **normal** $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact representation $\\mathcal{S}$ could vary depending on problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**...sometimes we have labels**\n",
    "\n",
    "  * i.e. $\\mathcal{S} = (x_i, y_i)_{i=1}^m$ where $y_i\\in \\{\\pm 1\\}$ are __anomaly__ labels;\n",
    "  * <span style=\"color: red\">**BUT** </span> normal observations are dominant class:\n",
    "  $$\n",
    "    \\overbrace{\\lvert i\\colon y_i = +1 \\rvert}^{n_+}\n",
    "        \\ll \\overbrace{\\lvert i\\colon y_i = -1 \\rvert}^{n_-}\n",
    "    \\,. $$\n",
    "\n",
    "\n",
    "$\\color{red}{\\Rightarrow}$ **imbalanced classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...sometimes we don't have labels\n",
    "\n",
    "  * $\\mathcal{S} = (x_i)_{i=1}^m$ -- **no labels!**;\n",
    "\n",
    "  * predict $\\alpha \\in (0, 1)$ -- level of anomalies.\n",
    "\n",
    "\n",
    "$\\color{red}{\\Rightarrow}$ **outlier detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use accuracy, precision, recall and $f1$-score to assess the quality of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pr_rc](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)\n",
    "\n",
    "\n",
    "$$\n",
    "    F_\\beta\n",
    "        = (1 + \\beta^2)\n",
    "            \\frac{\\text{Precision} \\cdot \\text{Recall}}\n",
    "                 {\\beta^2 \\, \\text{Precision} + \\text{Recall}}\n",
    "        = \\frac{\\beta + \\beta^{-1}}{\\beta\\frac{1}{\\text{Recall}} + \\beta^{-1}\\frac{1}{\\text{Precision}}}\n",
    "\\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 VAE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f9449c1734041c4af4637ea852c5ab0",
     "grade": false,
     "grade_id": "cell-dd7b1ea8d964f642",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    (Probabilistic) Encoder\n",
    "    Inference Model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Tanh(),\n",
    "            # nn.Linear(32, 32),\n",
    "            # nn.Tanh(),\n",
    "            # nn.Linear(32, 32),\n",
    "            # nn.Tanh(),\n",
    "        )\n",
    "        self.linear_mean = nn.Linear(32, 8)\n",
    "        self.linear_log_variance = nn.Linear(32, 8)\n",
    "\n",
    "    def reparameterize(self, mean, log_variance):\n",
    "        \"\"\"\n",
    "        Sample from normal distribution with reparameterization trick\n",
    "        I.e. z = \\mu + N(0, 1) \\sigma\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.fc1(x)\n",
    "        mean = self.linear_mean(h)\n",
    "        log_variance = self.linear_log_variance(h)\n",
    "        z = self.reparameterize(mean, log_variance)\n",
    "        return z, mean, log_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2354016ab8e1fc6bdbbf7e85ba09404",
     "grade": true,
     "grade_id": "cell-f59abaefb9c8661d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "encoder_test = Encoder()\n",
    "\n",
    "mu = torch.tensor(1000 * [0.])\n",
    "sigma = torch.tensor(1000 * [0.])\n",
    "\n",
    "assert encoder_test.reparameterize(mu, sigma).shape == (1000, )\n",
    "assert encoder_test.reparameterize(mu, sigma).mean().abs() < 7. / np.sqrt(1000.)\n",
    "\n",
    "mu = torch.tensor(10000 * [5.])\n",
    "sigma = torch.tensor(10000 * [1.])\n",
    "\n",
    "assert encoder_test.reparameterize(mu, sigma).shape == (10000, )\n",
    "assert (encoder_test.reparameterize(mu, sigma).mean().abs() - 5.) < np.exp(0.5) * 7. / np.sqrt(10000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Tanh(),\n",
    "            # nn.Linear(32, 32),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x_recon = self.fc1(z)\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mean, log_variance = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mean, log_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b245fd7ec9edcf0ff45049af65605e8",
     "grade": false,
     "grade_id": "cell-b68a8b6dff3577fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reconstruction_error(x_recon, x, reduction='sum'):\n",
    "    \"\"\"\n",
    "    MSE loss between x_recon and x\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    return reco_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8c2e99ef0e07494c3368b8d7ef05caf",
     "grade": true,
     "grade_id": "reconstruction_error",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np_testing.assert_approx_equal(\n",
    "    reconstruction_error(\n",
    "        torch.tensor([1., 2., 3.]),\n",
    "        torch.tensor([1., 2., 3.])\n",
    "    ),\n",
    "    0.\n",
    ")\n",
    "\n",
    "np_testing.assert_approx_equal(\n",
    "    reconstruction_error(\n",
    "        torch.tensor([1., 2., 3.]),\n",
    "        torch.tensor([1., 10., 3.])\n",
    "    ),\n",
    "    64.\n",
    ")\n",
    "\n",
    "np_testing.assert_approx_equal(\n",
    "    reconstruction_error(\n",
    "        torch.tensor([1., 2., 3.]),\n",
    "        torch.tensor([-1., 10., 3.1])\n",
    "    ),\n",
    "    68.01000213623047\n",
    ")\n",
    "\n",
    "np_testing.assert_approx_equal(\n",
    "    reconstruction_error(\n",
    "        torch.tensor([1., 2., 3.]),\n",
    "        torch.tensor([-1., 10., 3.1]), \n",
    "        reduction='mean'\n",
    "    ),\n",
    "    22.670000076293945\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c83d68a1f7649dd8b13ade2f75e61cc9",
     "grade": false,
     "grade_id": "cell-73a33ff5b24915c9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# see Appendix B from VAE paper:\n",
    "# Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "# https://arxiv.org/abs/1312.6114\n",
    "# 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "def kl_divergence(mean, log_variance):\n",
    "    \"\"\"\n",
    "    KL divergence between normal distribution with mean and log_variance and N(0, 1)\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f349674cf81b5a4e0ff7c5ab94d5ae",
     "grade": true,
     "grade_id": "kl_divergence",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np_testing.assert_approx_equal(\n",
    "    kl_divergence(torch.tensor(0.), torch.tensor(0.)).item(),\n",
    "    0.\n",
    ")\n",
    "\n",
    "np_testing.assert_approx_equal(\n",
    "    kl_divergence(torch.tensor(1.), torch.tensor(0.)).item(),\n",
    "    0.5\n",
    ")\n",
    "\n",
    "np_testing.assert_approx_equal(\n",
    "    kl_divergence(torch.tensor(2.), torch.tensor(np.log(5) * 2)).item(),\n",
    "    12.390563011169434\n",
    ")\n",
    "\n",
    "np_testing.assert_approx_equal(\n",
    "    kl_divergence(torch.tensor(-3.), torch.tensor(-5.)).item(),\n",
    "    6.503368854522705\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 Training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, device, reg_weight=1.):\n",
    "    model.train()    \n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mean, log_variance = model(data)\n",
    "        reco_error = reconstruction_error(recon_batch, data)\n",
    "        kld = kl_divergence(mean, log_variance)\n",
    "        loss = reco_error + kld * reg_weight\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    # accumulated loss\n",
    "    accum_reco_error = 0\n",
    "    accum_kld = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mean, log_variance = model(data)\n",
    "            \n",
    "            reco_error = reconstruction_error(recon_batch, data)\n",
    "            kld = kl_divergence(mean, log_variance)\n",
    "\n",
    "            accum_reco_error += reco_error.item()\n",
    "            accum_kld += kld.item()\n",
    "            \n",
    "    num_examples = len(data_loader.dataset)\n",
    "    \n",
    "    average_reco_error = accum_reco_error / num_examples\n",
    "    average_kld = accum_kld / num_examples\n",
    "    average_loss = average_reco_error + average_kld\n",
    "    return average_loss, (average_reco_error, average_kld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 RUN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_free_gpu():\n",
    "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount\n",
    "    nvmlInit()\n",
    "\n",
    "    return np.argmax([\n",
    "        nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(i)).free\n",
    "        for i in range(nvmlDeviceGetCount())\n",
    "    ])\n",
    "device = torch.device(\"cuda:{}\".format(get_free_gpu()))\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(torch.tensor(X_train).float(), batch_size=batch_size)\n",
    "valid_loader = DataLoader(torch.tensor(X_val).float(), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm.tqdm_notebook(range(1, epochs + 1)):\n",
    "    train(model, train_loader, optimizer, device, reg_weight=0.01)\n",
    "    \n",
    "    train_loss, (train_reco_error, train_kld) = test(model, train_loader, device)\n",
    "    valid_loss, (valid_reco_error, valid_kld) = test(model, valid_loader, device)\n",
    "    if epoch % 50 == 0:\n",
    "        print()\n",
    "        print(f'[Epoch: {epoch}/{epochs}] Training Loss: {train_loss:.4f} = Reconstruction Error ({train_reco_error:.4f}) + KL Divergence({train_kld:.4f})')\n",
    "        print(f'[Epoch: {epoch}/{epochs}] Validation Loss: {valid_loss:.4f} = Reconstruction Error ({valid_reco_error:.4f}) + KL Divergence({valid_kld:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm.tqdm_notebook(range(1, epochs + 1)):\n",
    "    train(model, train_loader, optimizer, device, reg_weight=0.05)\n",
    "    \n",
    "    train_loss, (train_reco_error, train_kld) = test(model, train_loader, device)\n",
    "    valid_loss, (valid_reco_error, valid_kld) = test(model, valid_loader, device)\n",
    "    if epoch % 50 == 0:\n",
    "        print()\n",
    "        print(f'[Epoch: {epoch}/{epochs}] Training Loss: {train_loss:.4f} = Reconstruction Error ({train_reco_error:.4f}) + KL Divergence({train_kld:.4f})')\n",
    "        print(f'[Epoch: {epoch}/{epochs}] Validation Loss: {valid_loss:.4f} = Reconstruction Error ({valid_reco_error:.4f}) + KL Divergence({valid_kld:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to sample from VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoder.eval()\n",
    "    z = torch.randn(512, 8).to(device) * 2\n",
    "    x_recon = decoder(z).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*x_recon.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Calculate anomaly score\n",
    "\n",
    "Anomaly score usually is defined as reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyVAE:\n",
    "    def __init__(self, model, device, threshold=0.):\n",
    "        self._model = model\n",
    "        self._threshold = threshold\n",
    "        self._device = device\n",
    "        \n",
    "    def decision_function(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().to(self._device)\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = x.to(self._device)\n",
    "        x_reco, _, _ = self._model(x)\n",
    "        score = -reconstruction_error(x_reco, x, reduction='none').mean(dim=1).cpu().detach().numpy()\n",
    "        return score\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return (self.decision_function(x) < -self._threshold) * 1.\n",
    "    \n",
    "    def set_threshold(self, threshold):\n",
    "        self._threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_vae = AnomalyVAE(model, device, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, X_test, y_test = create_dataset_moons(\n",
    "    train_size_pos=1, train_size_neg=1, test_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_error = -anomaly_vae.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = np.min(reco_error)\n",
    "max_error = np.max(reco_error)\n",
    "\n",
    "hist_kwargs  = {\n",
    "    'alpha': 0.5,\n",
    "    'range': (min_error, max_error),\n",
    "    'bins': 100,\n",
    "    'density': True\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.set_title(\"Anomaly score distribution for VAE\")\n",
    "_ = ax.hist(reco_error[y_test == 1], label='Normal class anomaly score', **hist_kwargs)\n",
    "_ = ax.hist(reco_error[y_test == 0], label='Anomaly class anomaly score', **hist_kwargs)\n",
    "ax.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "\n",
    "ax.set_title(\"Anomaly score distribution for VAE\")\n",
    "\n",
    "ax.boxplot([reco_error[y_test == 1], reco_error[y_test == 0]])\n",
    "ax.set_xticklabels(['Normal', 'Anomaly'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_level_lines(anomaly_vae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_vae = anomaly_vae.decision_function(X_test)\n",
    "labels_vae = anomaly_vae.predict(X_test)\n",
    "\n",
    "\n",
    "plot_results(y_test, predictions_vae)\n",
    "\n",
    "metrics_elliptic = classification_report(y_test, labels_vae, output_dict=True)\n",
    "print(classification_report(y_test, labels_vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
